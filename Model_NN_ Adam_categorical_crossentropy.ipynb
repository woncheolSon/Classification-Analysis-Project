{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_rows',38)\n",
    "pd.set_option('max_columns',25)\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import myslack_incomming\n",
    "\n",
    "# model\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.optimizers import SGD, RMSprop, Adadelta, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Activation, BatchNormalization\n",
    "import xgboost\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ver 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data shape: (95674, 5482)\n"
     ]
    }
   ],
   "source": [
    "train = pickle.load(open(\"./data/final_train_Ver1.pkl\", \"rb\"))\n",
    "print(\"test data shape: \"+str(train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data shape: (95674, 5481)\n"
     ]
    }
   ],
   "source": [
    "test = pickle.load(open(\"./data/final_test_Ver1.pkl\", \"rb\"))\n",
    "print(\"test data shape: \"+str(test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - sample_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission data shape: (95674, 39)\n"
     ]
    }
   ],
   "source": [
    "samplesub = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "print(\"sample_submission data shape: \"+str(samplesub.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling 8 - Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_X, Train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns='TripType')\n",
    "y = train['TripType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, array([999,  30,  26,   8,  35,  41,  21,   6,  42,   7,   9,  39,  25,\n",
       "         38,  15,  36,  20,  37,  32,  40,   5,   3,   4,  24,  33,  43,\n",
       "         31,  27,  34,  18,  29,  44,  19,  23,  22,  28,  14,  12]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y.unique()), y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([999,  30,  26,   8,  35,  41,  21,   6,  42,   7,   9,  39,  25,\n",
       "        38,  15,  36,  20,  37,  32,  40,   5,   3,   4,  24,  33,  43,\n",
       "        31,  27,  34,  18,  29,  44,  19,  23,  22,  28,  14,  12])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37, 22, 18,  5, 27, 33, 13,  3, 34,  4,  6, 31, 17, 30,  9, 28, 12,\n",
       "       29, 24, 32,  2,  0,  1, 16, 25, 35, 23, 19, 26, 10, 21, 36, 11, 15,\n",
       "       14, 20,  8,  7])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.LabelEncoder().fit_transform(y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['TripType'].replace(y.unique(),preprocessing.LabelEncoder().fit_transform(y.unique()),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, array([37, 22, 18,  5, 27, 33, 13,  3, 34,  4,  6, 31, 17, 30,  9, 28, 12,\n",
       "        29, 24, 32,  2,  0,  1, 16, 25, 35, 23, 19, 26, 10, 21, 36, 11, 15,\n",
       "        14, 20,  8,  7]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y.unique()), y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<95674x5481 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1124112 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = csr_matrix(X); X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<95674x5481 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1130483 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csr_test = csr_matrix(test); csr_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76539, 19135, 76539, 19135)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train0, y_test0 = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train.shape[0], X_test.shape[0], len(y_train0), len(y_test0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train0, 38)\n",
    "Y_test = np_utils.to_categorical(y_test0, 38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = 100\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NN_model_Adam = Sequential()\n",
    "NN_model_Adam.add(Dense(dense, input_dim=5481, kernel_initializer=\"glorot_uniform\"))\n",
    "NN_model_Adam.add(BatchNormalization())\n",
    "NN_model_Adam.add(Activation('relu'))\n",
    "NN_model_Adam.add(Dense(38, activation=\"softmax\", kernel_initializer=\"glorot_uniform\"))\n",
    "NN_model_Adam.compile(optimizer=Adam(lr=lr), loss='categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 100)               548200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 38)                3838      \n",
      "=================================================================\n",
      "Total params: 552,438\n",
      "Trainable params: 552,238\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model_Adam.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76539 samples, validate on 19135 samples\n",
      "Epoch 1/200\n",
      "76539/76539 [==============================] - 5s 68us/step - loss: 3.1959 - acc: 0.1621 - val_loss: 2.6651 - val_acc: 0.2748\n",
      "Epoch 2/200\n",
      "76539/76539 [==============================] - 5s 63us/step - loss: 2.1826 - acc: 0.4718 - val_loss: 2.0388 - val_acc: 0.5213\n",
      "Epoch 3/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 1.6459 - acc: 0.6203 - val_loss: 1.6899 - val_acc: 0.5888\n",
      "Epoch 4/200\n",
      "76539/76539 [==============================] - 5s 67us/step - loss: 1.3269 - acc: 0.6705 - val_loss: 1.4945 - val_acc: 0.6187\n",
      "Epoch 5/200\n",
      "76539/76539 [==============================] - 5s 66us/step - loss: 1.1171 - acc: 0.7115 - val_loss: 1.3685 - val_acc: 0.6303\n",
      "Epoch 6/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.9667 - acc: 0.7449 - val_loss: 1.2764 - val_acc: 0.6445\n",
      "Epoch 7/200\n",
      "76539/76539 [==============================] - 5s 69us/step - loss: 0.8503 - acc: 0.7752 - val_loss: 1.2191 - val_acc: 0.6469\n",
      "Epoch 8/200\n",
      "76539/76539 [==============================] - 5s 63us/step - loss: 0.7585 - acc: 0.8006 - val_loss: 1.1753 - val_acc: 0.6504\n",
      "Epoch 9/200\n",
      "76539/76539 [==============================] - 5s 66us/step - loss: 0.6831 - acc: 0.8196 - val_loss: 1.1443 - val_acc: 0.6527\n",
      "Epoch 10/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.6209 - acc: 0.8389 - val_loss: 1.1277 - val_acc: 0.6539\n",
      "Epoch 11/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.5676 - acc: 0.8557 - val_loss: 1.0992 - val_acc: 0.6600\n",
      "Epoch 12/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.5215 - acc: 0.8704 - val_loss: 1.0864 - val_acc: 0.6624\n",
      "Epoch 13/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.4824 - acc: 0.8812 - val_loss: 1.0908 - val_acc: 0.6591\n",
      "Epoch 14/200\n",
      "76539/76539 [==============================] - 5s 68us/step - loss: 0.4485 - acc: 0.8917 - val_loss: 1.0612 - val_acc: 0.6681\n",
      "Epoch 15/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.4182 - acc: 0.9001 - val_loss: 1.0618 - val_acc: 0.6691\n",
      "Epoch 16/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.3910 - acc: 0.9085 - val_loss: 1.0780 - val_acc: 0.6662\n",
      "Epoch 17/200\n",
      "76539/76539 [==============================] - 5s 63us/step - loss: 0.3673 - acc: 0.9152 - val_loss: 1.0738 - val_acc: 0.6697\n",
      "Epoch 18/200\n",
      "76539/76539 [==============================] - 5s 67us/step - loss: 0.3451 - acc: 0.9220 - val_loss: 1.0596 - val_acc: 0.6744\n",
      "Epoch 19/200\n",
      "76539/76539 [==============================] - 5s 67us/step - loss: 0.3249 - acc: 0.9274 - val_loss: 1.0897 - val_acc: 0.6704\n",
      "Epoch 20/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.3079 - acc: 0.9320 - val_loss: 1.0703 - val_acc: 0.6754\n",
      "Epoch 21/200\n",
      "76539/76539 [==============================] - 5s 66us/step - loss: 0.2919 - acc: 0.9355 - val_loss: 1.0749 - val_acc: 0.6788\n",
      "Epoch 22/200\n",
      "76539/76539 [==============================] - 5s 68us/step - loss: 0.2779 - acc: 0.9407 - val_loss: 1.0821 - val_acc: 0.6810\n",
      "Epoch 23/200\n",
      "76539/76539 [==============================] - 5s 67us/step - loss: 0.2640 - acc: 0.9445 - val_loss: 1.0827 - val_acc: 0.6815\n",
      "Epoch 24/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.2515 - acc: 0.9469 - val_loss: 1.1042 - val_acc: 0.6794\n",
      "Epoch 25/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.2402 - acc: 0.9500 - val_loss: 1.1005 - val_acc: 0.6845\n",
      "Epoch 26/200\n",
      "76539/76539 [==============================] - 5s 63us/step - loss: 0.2296 - acc: 0.9525 - val_loss: 1.1124 - val_acc: 0.6829\n",
      "Epoch 27/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.2192 - acc: 0.9556 - val_loss: 1.1294 - val_acc: 0.6807\n",
      "Epoch 28/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.2104 - acc: 0.9581 - val_loss: 1.1373 - val_acc: 0.6829\n",
      "Epoch 29/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.2030 - acc: 0.9591 - val_loss: 1.1345 - val_acc: 0.6847\n",
      "Epoch 30/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.1943 - acc: 0.9615 - val_loss: 1.1630 - val_acc: 0.6809\n",
      "Epoch 31/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.1867 - acc: 0.9633 - val_loss: 1.1487 - val_acc: 0.6865\n",
      "Epoch 32/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.1809 - acc: 0.9643 - val_loss: 1.1570 - val_acc: 0.6862\n",
      "Epoch 33/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.1738 - acc: 0.9661 - val_loss: 1.1817 - val_acc: 0.6842\n",
      "Epoch 34/200\n",
      "76539/76539 [==============================] - 5s 63us/step - loss: 0.1666 - acc: 0.9678 - val_loss: 1.2020 - val_acc: 0.6814\n",
      "Epoch 35/200\n",
      "76539/76539 [==============================] - 5s 66us/step - loss: 0.1631 - acc: 0.9683 - val_loss: 1.1957 - val_acc: 0.6860\n",
      "Epoch 36/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.1565 - acc: 0.9694 - val_loss: 1.2050 - val_acc: 0.6854\n",
      "Epoch 37/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.1510 - acc: 0.9708 - val_loss: 1.2226 - val_acc: 0.6834\n",
      "Epoch 38/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.1463 - acc: 0.9715 - val_loss: 1.2405 - val_acc: 0.6820\n",
      "Epoch 39/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.1417 - acc: 0.9725 - val_loss: 1.2618 - val_acc: 0.6805\n",
      "Epoch 40/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.1381 - acc: 0.9734 - val_loss: 1.2493 - val_acc: 0.6845\n",
      "Epoch 41/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.1328 - acc: 0.9745 - val_loss: 1.2804 - val_acc: 0.6809\n",
      "Epoch 42/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.1291 - acc: 0.9757 - val_loss: 1.2807 - val_acc: 0.6814\n",
      "Epoch 43/200\n",
      "76539/76539 [==============================] - 5s 63us/step - loss: 0.1250 - acc: 0.9761 - val_loss: 1.3033 - val_acc: 0.6802\n",
      "Epoch 44/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.1219 - acc: 0.9764 - val_loss: 1.3044 - val_acc: 0.6819\n",
      "Epoch 45/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.1196 - acc: 0.9771 - val_loss: 1.3142 - val_acc: 0.6815\n",
      "Epoch 46/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.1169 - acc: 0.9776 - val_loss: 1.3171 - val_acc: 0.6813\n",
      "Epoch 47/200\n",
      "76539/76539 [==============================] - 5s 70us/step - loss: 0.1150 - acc: 0.9773 - val_loss: 1.3433 - val_acc: 0.6784\n",
      "Epoch 48/200\n",
      "76539/76539 [==============================] - 6s 74us/step - loss: 0.1112 - acc: 0.9784 - val_loss: 1.3372 - val_acc: 0.6830\n",
      "Epoch 49/200\n",
      "76539/76539 [==============================] - 5s 66us/step - loss: 0.1076 - acc: 0.9796 - val_loss: 1.3621 - val_acc: 0.6797\n",
      "Epoch 50/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.1042 - acc: 0.9797 - val_loss: 1.3657 - val_acc: 0.6822\n",
      "Epoch 51/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.1015 - acc: 0.9806 - val_loss: 1.3569 - val_acc: 0.6845\n",
      "Epoch 52/200\n",
      "76539/76539 [==============================] - 5s 63us/step - loss: 0.1000 - acc: 0.9810 - val_loss: 1.3699 - val_acc: 0.6829\n",
      "Epoch 53/200\n",
      "76539/76539 [==============================] - 5s 63us/step - loss: 0.0984 - acc: 0.9811 - val_loss: 1.3838 - val_acc: 0.6820\n",
      "Epoch 54/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.0953 - acc: 0.9813 - val_loss: 1.3891 - val_acc: 0.6816\n",
      "Epoch 55/200\n",
      "76539/76539 [==============================] - 5s 63us/step - loss: 0.0947 - acc: 0.9815 - val_loss: 1.3884 - val_acc: 0.6826\n",
      "Epoch 56/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.0916 - acc: 0.9822 - val_loss: 1.4159 - val_acc: 0.6784\n",
      "Epoch 57/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.0897 - acc: 0.9821 - val_loss: 1.4395 - val_acc: 0.6790\n",
      "Epoch 58/200\n",
      "76539/76539 [==============================] - 5s 66us/step - loss: 0.0880 - acc: 0.9824 - val_loss: 1.4712 - val_acc: 0.6745\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76539/76539 [==============================] - 5s 69us/step - loss: 0.0877 - acc: 0.9818 - val_loss: 1.4758 - val_acc: 0.6767\n",
      "Epoch 60/200\n",
      "76539/76539 [==============================] - 5s 67us/step - loss: 0.0859 - acc: 0.9827 - val_loss: 1.4287 - val_acc: 0.6822\n",
      "Epoch 61/200\n",
      "76539/76539 [==============================] - 5s 68us/step - loss: 0.0824 - acc: 0.9836 - val_loss: 1.4521 - val_acc: 0.6804\n",
      "Epoch 62/200\n",
      "76539/76539 [==============================] - 6s 77us/step - loss: 0.0819 - acc: 0.9831 - val_loss: 1.4756 - val_acc: 0.6776\n",
      "Epoch 63/200\n",
      "76539/76539 [==============================] - 6s 75us/step - loss: 0.0822 - acc: 0.9824 - val_loss: 1.4652 - val_acc: 0.6812\n",
      "Epoch 64/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.0790 - acc: 0.9834 - val_loss: 1.5089 - val_acc: 0.6752\n",
      "Epoch 65/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.0767 - acc: 0.9844 - val_loss: 1.4676 - val_acc: 0.6829\n",
      "Epoch 66/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.0773 - acc: 0.9831 - val_loss: 1.5161 - val_acc: 0.6756\n",
      "Epoch 67/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.0745 - acc: 0.9850 - val_loss: 1.5399 - val_acc: 0.6738\n",
      "Epoch 68/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.0732 - acc: 0.9845 - val_loss: 1.5363 - val_acc: 0.6760\n",
      "Epoch 69/200\n",
      "76539/76539 [==============================] - 5s 71us/step - loss: 0.0728 - acc: 0.9846 - val_loss: 1.4987 - val_acc: 0.6817\n",
      "Epoch 70/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.0703 - acc: 0.9854 - val_loss: 1.5167 - val_acc: 0.6796\n",
      "Epoch 71/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.0686 - acc: 0.9855 - val_loss: 1.5306 - val_acc: 0.6776\n",
      "Epoch 72/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.0680 - acc: 0.9855 - val_loss: 1.5535 - val_acc: 0.6770\n",
      "Epoch 73/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.0666 - acc: 0.9859 - val_loss: 1.5668 - val_acc: 0.6766\n",
      "Epoch 74/200\n",
      "76539/76539 [==============================] - 6s 74us/step - loss: 0.0653 - acc: 0.9859 - val_loss: 1.5611 - val_acc: 0.6766\n",
      "Epoch 75/200\n",
      "76539/76539 [==============================] - 5s 71us/step - loss: 0.0641 - acc: 0.9857 - val_loss: 1.5800 - val_acc: 0.6754\n",
      "Epoch 76/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.0640 - acc: 0.9860 - val_loss: 1.5825 - val_acc: 0.6758\n",
      "Epoch 77/200\n",
      "76539/76539 [==============================] - 5s 67us/step - loss: 0.0631 - acc: 0.9860 - val_loss: 1.5748 - val_acc: 0.6771\n",
      "Epoch 78/200\n",
      "76539/76539 [==============================] - 6s 72us/step - loss: 0.0618 - acc: 0.9866 - val_loss: 1.5877 - val_acc: 0.6770\n",
      "Epoch 79/200\n",
      "76539/76539 [==============================] - 5s 68us/step - loss: 0.0608 - acc: 0.9865 - val_loss: 1.6049 - val_acc: 0.6742\n",
      "Epoch 80/200\n",
      "76539/76539 [==============================] - 6s 74us/step - loss: 0.0604 - acc: 0.9865 - val_loss: 1.6069 - val_acc: 0.6756\n",
      "Epoch 81/200\n",
      "76539/76539 [==============================] - 5s 68us/step - loss: 0.0599 - acc: 0.9869 - val_loss: 1.6093 - val_acc: 0.6762\n",
      "Epoch 82/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.0635 - acc: 0.9856 - val_loss: 1.6102 - val_acc: 0.6770\n",
      "Epoch 83/200\n",
      "76539/76539 [==============================] - 5s 63us/step - loss: 0.0626 - acc: 0.9854 - val_loss: 1.6508 - val_acc: 0.6704\n",
      "Epoch 84/200\n",
      "76539/76539 [==============================] - 5s 66us/step - loss: 0.0625 - acc: 0.9859 - val_loss: 1.6300 - val_acc: 0.6771\n",
      "Epoch 85/200\n",
      "76539/76539 [==============================] - 5s 69us/step - loss: 0.0609 - acc: 0.9862 - val_loss: 1.6192 - val_acc: 0.6771\n",
      "Epoch 86/200\n",
      "76539/76539 [==============================] - 5s 72us/step - loss: 0.0578 - acc: 0.9872 - val_loss: 1.6069 - val_acc: 0.6796\n",
      "Epoch 87/200\n",
      "76539/76539 [==============================] - 5s 66us/step - loss: 0.0568 - acc: 0.9869 - val_loss: 1.6348 - val_acc: 0.6765\n",
      "Epoch 88/200\n",
      "76539/76539 [==============================] - 5s 70us/step - loss: 0.0543 - acc: 0.9873 - val_loss: 1.6354 - val_acc: 0.6768\n",
      "Epoch 89/200\n",
      "76539/76539 [==============================] - 5s 69us/step - loss: 0.0535 - acc: 0.9876 - val_loss: 1.6520 - val_acc: 0.6753\n",
      "Epoch 90/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.0536 - acc: 0.9874 - val_loss: 1.6736 - val_acc: 0.6727\n",
      "Epoch 91/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.0529 - acc: 0.9872 - val_loss: 1.6487 - val_acc: 0.6766\n",
      "Epoch 92/200\n",
      "76539/76539 [==============================] - 5s 67us/step - loss: 0.0521 - acc: 0.9878 - val_loss: 1.6720 - val_acc: 0.6751\n",
      "Epoch 93/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.0518 - acc: 0.9872 - val_loss: 1.7081 - val_acc: 0.6712\n",
      "Epoch 94/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.0501 - acc: 0.9880 - val_loss: 1.6776 - val_acc: 0.6738\n",
      "Epoch 95/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.0499 - acc: 0.9874 - val_loss: 1.6986 - val_acc: 0.6732\n",
      "Epoch 96/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.0502 - acc: 0.9877 - val_loss: 1.7375 - val_acc: 0.6703\n",
      "Epoch 97/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.0504 - acc: 0.9876 - val_loss: 1.7031 - val_acc: 0.6750\n",
      "Epoch 98/200\n",
      "76539/76539 [==============================] - 5s 67us/step - loss: 0.0486 - acc: 0.9880 - val_loss: 1.7201 - val_acc: 0.6715\n",
      "Epoch 99/200\n",
      "76539/76539 [==============================] - 5s 68us/step - loss: 0.0477 - acc: 0.9881 - val_loss: 1.7127 - val_acc: 0.6758\n",
      "Epoch 100/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.0482 - acc: 0.9880 - val_loss: 1.7384 - val_acc: 0.6712\n",
      "Epoch 101/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.0477 - acc: 0.9880 - val_loss: 1.7486 - val_acc: 0.6714\n",
      "Epoch 102/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.0473 - acc: 0.9881 - val_loss: 1.7418 - val_acc: 0.6724\n",
      "Epoch 103/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.0466 - acc: 0.9883 - val_loss: 1.7626 - val_acc: 0.6712\n",
      "Epoch 104/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.0453 - acc: 0.9882 - val_loss: 1.7467 - val_acc: 0.6716\n",
      "Epoch 105/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.0443 - acc: 0.9886 - val_loss: 1.7776 - val_acc: 0.6707\n",
      "Epoch 106/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.0439 - acc: 0.9887 - val_loss: 1.7550 - val_acc: 0.6736\n",
      "Epoch 107/200\n",
      "76539/76539 [==============================] - 5s 67us/step - loss: 0.0439 - acc: 0.9887 - val_loss: 1.7808 - val_acc: 0.6697\n",
      "Epoch 108/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.0436 - acc: 0.9886 - val_loss: 1.7986 - val_acc: 0.6696\n",
      "Epoch 109/200\n",
      "76539/76539 [==============================] - 5s 63us/step - loss: 0.0436 - acc: 0.9887 - val_loss: 1.7558 - val_acc: 0.6743\n",
      "Epoch 110/200\n",
      "76539/76539 [==============================] - 5s 63us/step - loss: 0.0427 - acc: 0.9888 - val_loss: 1.7952 - val_acc: 0.6711\n",
      "Epoch 111/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.0424 - acc: 0.9889 - val_loss: 1.8047 - val_acc: 0.6702\n",
      "Epoch 112/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.0420 - acc: 0.9889 - val_loss: 1.7907 - val_acc: 0.6695\n",
      "Epoch 113/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.0428 - acc: 0.9885 - val_loss: 1.8057 - val_acc: 0.6696\n",
      "Epoch 114/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.0424 - acc: 0.9884 - val_loss: 1.7978 - val_acc: 0.6722\n",
      "Epoch 115/200\n",
      "76539/76539 [==============================] - 5s 63us/step - loss: 0.0420 - acc: 0.9885 - val_loss: 1.8093 - val_acc: 0.6721\n",
      "Epoch 116/200\n",
      "76539/76539 [==============================] - 5s 63us/step - loss: 0.0418 - acc: 0.9887 - val_loss: 1.8039 - val_acc: 0.6718\n",
      "Epoch 117/200\n",
      "76539/76539 [==============================] - 5s 67us/step - loss: 0.0416 - acc: 0.9882 - val_loss: 1.8309 - val_acc: 0.6701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.0409 - acc: 0.9884 - val_loss: 1.8465 - val_acc: 0.6679\n",
      "Epoch 119/200\n",
      "76539/76539 [==============================] - 5s 66us/step - loss: 0.0406 - acc: 0.9882 - val_loss: 1.8379 - val_acc: 0.6677\n",
      "Epoch 120/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.0399 - acc: 0.9889 - val_loss: 1.8466 - val_acc: 0.6687\n",
      "Epoch 121/200\n",
      "76539/76539 [==============================] - 5s 63us/step - loss: 0.0390 - acc: 0.9892 - val_loss: 1.8383 - val_acc: 0.6695\n",
      "Epoch 122/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.0391 - acc: 0.9888 - val_loss: 1.8143 - val_acc: 0.6724\n",
      "Epoch 123/200\n",
      "76539/76539 [==============================] - 5s 61us/step - loss: 0.0395 - acc: 0.9885 - val_loss: 1.8827 - val_acc: 0.6658\n",
      "Epoch 124/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.0387 - acc: 0.9892 - val_loss: 1.8396 - val_acc: 0.6702\n",
      "Epoch 125/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.0384 - acc: 0.9889 - val_loss: 1.8576 - val_acc: 0.6678\n",
      "Epoch 126/200\n",
      "76539/76539 [==============================] - 5s 63us/step - loss: 0.0389 - acc: 0.9892 - val_loss: 1.8636 - val_acc: 0.6693\n",
      "Epoch 127/200\n",
      "76539/76539 [==============================] - 5s 61us/step - loss: 0.0388 - acc: 0.9885 - val_loss: 1.8708 - val_acc: 0.6685\n",
      "Epoch 128/200\n",
      "76539/76539 [==============================] - 5s 66us/step - loss: 0.0379 - acc: 0.9886 - val_loss: 1.8739 - val_acc: 0.6665\n",
      "Epoch 129/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.0371 - acc: 0.9891 - val_loss: 1.8970 - val_acc: 0.6684\n",
      "Epoch 130/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.0370 - acc: 0.9891 - val_loss: 1.9136 - val_acc: 0.6655\n",
      "Epoch 131/200\n",
      "76539/76539 [==============================] - 5s 71us/step - loss: 0.0367 - acc: 0.9894 - val_loss: 1.9230 - val_acc: 0.6639\n",
      "Epoch 132/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.0366 - acc: 0.9893 - val_loss: 1.8738 - val_acc: 0.6701\n",
      "Epoch 133/200\n",
      "76539/76539 [==============================] - 5s 68us/step - loss: 0.0359 - acc: 0.9894 - val_loss: 1.9268 - val_acc: 0.6659\n",
      "Epoch 134/200\n",
      "76539/76539 [==============================] - 5s 68us/step - loss: 0.0356 - acc: 0.9895 - val_loss: 1.9074 - val_acc: 0.6673\n",
      "Epoch 135/200\n",
      "76539/76539 [==============================] - 5s 69us/step - loss: 0.0356 - acc: 0.9893 - val_loss: 1.8812 - val_acc: 0.6699\n",
      "Epoch 136/200\n",
      "76539/76539 [==============================] - 6s 73us/step - loss: 0.0356 - acc: 0.9893 - val_loss: 1.9131 - val_acc: 0.6667\n",
      "Epoch 137/200\n",
      "76539/76539 [==============================] - 5s 66us/step - loss: 0.0354 - acc: 0.9892 - val_loss: 1.9095 - val_acc: 0.6691\n",
      "Epoch 138/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.0351 - acc: 0.9896 - val_loss: 1.9239 - val_acc: 0.6683\n",
      "Epoch 139/200\n",
      "76539/76539 [==============================] - 5s 70us/step - loss: 0.0353 - acc: 0.9891 - val_loss: 1.9675 - val_acc: 0.6641\n",
      "Epoch 140/200\n",
      "76539/76539 [==============================] - 5s 67us/step - loss: 0.0354 - acc: 0.9893 - val_loss: 1.9148 - val_acc: 0.6695\n",
      "Epoch 141/200\n",
      "76539/76539 [==============================] - 5s 66us/step - loss: 0.0348 - acc: 0.9895 - val_loss: 1.9524 - val_acc: 0.6668\n",
      "Epoch 142/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.0348 - acc: 0.9890 - val_loss: 1.9528 - val_acc: 0.6670\n",
      "Epoch 143/200\n",
      "76539/76539 [==============================] - 5s 68us/step - loss: 0.0354 - acc: 0.9890 - val_loss: 1.9312 - val_acc: 0.6682\n",
      "Epoch 144/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.0345 - acc: 0.9894 - val_loss: 1.9392 - val_acc: 0.6678\n",
      "Epoch 145/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.0336 - acc: 0.9895 - val_loss: 1.9572 - val_acc: 0.6667\n",
      "Epoch 146/200\n",
      "76539/76539 [==============================] - 5s 66us/step - loss: 0.0336 - acc: 0.9894 - val_loss: 1.9664 - val_acc: 0.6663\n",
      "Epoch 147/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.0334 - acc: 0.9897 - val_loss: 1.9995 - val_acc: 0.6652\n",
      "Epoch 148/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.0337 - acc: 0.9893 - val_loss: 1.9771 - val_acc: 0.6637\n",
      "Epoch 149/200\n",
      "76539/76539 [==============================] - 5s 69us/step - loss: 0.0332 - acc: 0.9896 - val_loss: 1.9493 - val_acc: 0.6708\n",
      "Epoch 150/200\n",
      "76539/76539 [==============================] - 5s 63us/step - loss: 0.0349 - acc: 0.9886 - val_loss: 1.9776 - val_acc: 0.6673\n",
      "Epoch 151/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.0330 - acc: 0.9894 - val_loss: 1.9779 - val_acc: 0.6677\n",
      "Epoch 152/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.0348 - acc: 0.9890 - val_loss: 1.9564 - val_acc: 0.6700\n",
      "Epoch 153/200\n",
      "76539/76539 [==============================] - 5s 63us/step - loss: 0.0337 - acc: 0.9893 - val_loss: 1.9798 - val_acc: 0.6657\n",
      "Epoch 154/200\n",
      "76539/76539 [==============================] - 5s 70us/step - loss: 0.0331 - acc: 0.9891 - val_loss: 1.9913 - val_acc: 0.6649\n",
      "Epoch 155/200\n",
      "76539/76539 [==============================] - 5s 69us/step - loss: 0.0334 - acc: 0.9895 - val_loss: 1.9958 - val_acc: 0.6646\n",
      "Epoch 156/200\n",
      "76539/76539 [==============================] - 5s 66us/step - loss: 0.0322 - acc: 0.9896 - val_loss: 1.9866 - val_acc: 0.6667\n",
      "Epoch 157/200\n",
      "76539/76539 [==============================] - 5s 67us/step - loss: 0.0321 - acc: 0.9898 - val_loss: 1.9910 - val_acc: 0.6672\n",
      "Epoch 158/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.0327 - acc: 0.9894 - val_loss: 2.0021 - val_acc: 0.6662\n",
      "Epoch 159/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.0327 - acc: 0.9894 - val_loss: 2.0199 - val_acc: 0.6653\n",
      "Epoch 160/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.0323 - acc: 0.9895 - val_loss: 1.9821 - val_acc: 0.6700\n",
      "Epoch 161/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.0321 - acc: 0.9894 - val_loss: 1.9924 - val_acc: 0.6691\n",
      "Epoch 162/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.0315 - acc: 0.9894 - val_loss: 1.9984 - val_acc: 0.6665\n",
      "Epoch 163/200\n",
      "76539/76539 [==============================] - 5s 63us/step - loss: 0.0317 - acc: 0.9894 - val_loss: 2.0245 - val_acc: 0.6659\n",
      "Epoch 164/200\n",
      "76539/76539 [==============================] - 5s 70us/step - loss: 0.0315 - acc: 0.9897 - val_loss: 2.0258 - val_acc: 0.6652\n",
      "Epoch 165/200\n",
      "76539/76539 [==============================] - 5s 69us/step - loss: 0.0318 - acc: 0.9895 - val_loss: 2.0253 - val_acc: 0.6660\n",
      "Epoch 166/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.0320 - acc: 0.9895 - val_loss: 2.0547 - val_acc: 0.6630\n",
      "Epoch 167/200\n",
      "76539/76539 [==============================] - 5s 69us/step - loss: 0.0334 - acc: 0.9893 - val_loss: 2.0039 - val_acc: 0.6668\n",
      "Epoch 168/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.0340 - acc: 0.9890 - val_loss: 2.0221 - val_acc: 0.6667\n",
      "Epoch 169/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.0355 - acc: 0.9887 - val_loss: 1.9811 - val_acc: 0.6723\n",
      "Epoch 170/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.0438 - acc: 0.9865 - val_loss: 2.0084 - val_acc: 0.6707\n",
      "Epoch 171/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.0502 - acc: 0.9855 - val_loss: 2.0476 - val_acc: 0.6676\n",
      "Epoch 172/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.0532 - acc: 0.9845 - val_loss: 2.0229 - val_acc: 0.6679\n",
      "Epoch 173/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.0524 - acc: 0.9851 - val_loss: 2.0070 - val_acc: 0.6711\n",
      "Epoch 174/200\n",
      "76539/76539 [==============================] - 5s 63us/step - loss: 0.0455 - acc: 0.9876 - val_loss: 2.0161 - val_acc: 0.6738\n",
      "Epoch 175/200\n",
      "76539/76539 [==============================] - 5s 72us/step - loss: 0.0404 - acc: 0.9888 - val_loss: 2.0095 - val_acc: 0.6744\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76539/76539 [==============================] - 5s 69us/step - loss: 0.0379 - acc: 0.9887 - val_loss: 1.9982 - val_acc: 0.6746\n",
      "Epoch 177/200\n",
      "76539/76539 [==============================] - 5s 67us/step - loss: 0.0356 - acc: 0.9893 - val_loss: 1.9769 - val_acc: 0.6750\n",
      "Epoch 178/200\n",
      "76539/76539 [==============================] - 5s 66us/step - loss: 0.0341 - acc: 0.9889 - val_loss: 2.0111 - val_acc: 0.6737\n",
      "Epoch 179/200\n",
      "76539/76539 [==============================] - 5s 63us/step - loss: 0.0324 - acc: 0.9898 - val_loss: 1.9960 - val_acc: 0.6737\n",
      "Epoch 180/200\n",
      "76539/76539 [==============================] - 5s 68us/step - loss: 0.0313 - acc: 0.9896 - val_loss: 2.0129 - val_acc: 0.6722\n",
      "Epoch 181/200\n",
      "76539/76539 [==============================] - 5s 71us/step - loss: 0.0329 - acc: 0.9891 - val_loss: 2.0162 - val_acc: 0.6717\n",
      "Epoch 182/200\n",
      "76539/76539 [==============================] - 5s 70us/step - loss: 0.0308 - acc: 0.9898 - val_loss: 2.0512 - val_acc: 0.6698\n",
      "Epoch 183/200\n",
      "76539/76539 [==============================] - 5s 70us/step - loss: 0.0301 - acc: 0.9897 - val_loss: 2.0516 - val_acc: 0.6698\n",
      "Epoch 184/200\n",
      "76539/76539 [==============================] - 5s 70us/step - loss: 0.0298 - acc: 0.9902 - val_loss: 2.0599 - val_acc: 0.6692\n",
      "Epoch 185/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.0304 - acc: 0.9897 - val_loss: 2.0326 - val_acc: 0.6701\n",
      "Epoch 186/200\n",
      "76539/76539 [==============================] - 5s 72us/step - loss: 0.0301 - acc: 0.9898 - val_loss: 2.0517 - val_acc: 0.6693\n",
      "Epoch 187/200\n",
      "76539/76539 [==============================] - 5s 64us/step - loss: 0.0292 - acc: 0.9903 - val_loss: 2.0635 - val_acc: 0.6681\n",
      "Epoch 188/200\n",
      "76539/76539 [==============================] - 5s 66us/step - loss: 0.0297 - acc: 0.9899 - val_loss: 2.0467 - val_acc: 0.6684\n",
      "Epoch 189/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.0297 - acc: 0.9898 - val_loss: 2.0691 - val_acc: 0.6671\n",
      "Epoch 190/200\n",
      "76539/76539 [==============================] - 5s 66us/step - loss: 0.0290 - acc: 0.9900 - val_loss: 2.0658 - val_acc: 0.6692\n",
      "Epoch 191/200\n",
      "76539/76539 [==============================] - 5s 63us/step - loss: 0.0296 - acc: 0.9898 - val_loss: 2.0611 - val_acc: 0.6692\n",
      "Epoch 192/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.0291 - acc: 0.9899 - val_loss: 2.0724 - val_acc: 0.6686\n",
      "Epoch 193/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.0283 - acc: 0.9902 - val_loss: 2.0893 - val_acc: 0.6666\n",
      "Epoch 194/200\n",
      "76539/76539 [==============================] - 5s 66us/step - loss: 0.0284 - acc: 0.9901 - val_loss: 2.0946 - val_acc: 0.6671\n",
      "Epoch 195/200\n",
      "76539/76539 [==============================] - 5s 62us/step - loss: 0.0288 - acc: 0.9900 - val_loss: 2.0796 - val_acc: 0.6681\n",
      "Epoch 196/200\n",
      "76539/76539 [==============================] - 5s 66us/step - loss: 0.0279 - acc: 0.9901 - val_loss: 2.1258 - val_acc: 0.6655\n",
      "Epoch 197/200\n",
      "76539/76539 [==============================] - 5s 66us/step - loss: 0.0282 - acc: 0.9903 - val_loss: 2.0865 - val_acc: 0.6689\n",
      "Epoch 198/200\n",
      "76539/76539 [==============================] - 5s 65us/step - loss: 0.0281 - acc: 0.9900 - val_loss: 2.1217 - val_acc: 0.6641\n",
      "Epoch 199/200\n",
      "76539/76539 [==============================] - 5s 66us/step - loss: 0.0285 - acc: 0.9896 - val_loss: 2.1071 - val_acc: 0.6677\n",
      "Epoch 200/200\n",
      "76539/76539 [==============================] - 5s 68us/step - loss: 0.0278 - acc: 0.9901 - val_loss: 2.1351 - val_acc: 0.6647\n",
      "<Response [200]>\n",
      "CPU times: user 40min 31s, sys: 7min 5s, total: 47min 36s\n",
      "Wall time: 16min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hist = NN_model_Adam.fit(X_train, Y_train, \n",
    "                              epochs=epochs, batch_size=batch_size, \n",
    "                              validation_data=(X_test, Y_test), \n",
    "                              verbose=1)\n",
    "\n",
    "myslack_incomming.send_slack('Adam finish! dense: {}, lr: {},  val_acc: {} '\n",
    "                             .format(dense,lr,hist.history['val_acc'][-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  6, 32, ...,  6,  6, 28])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 642,    0,    1, ...,    1,    0,   29],\n",
       "       [   0,   50,    4, ...,    0,    0,    0],\n",
       "       [   1,    3,  770, ...,    0,    2,    9],\n",
       "       ...,\n",
       "       [   1,    1,   13, ...,   10,    6,    3],\n",
       "       [   0,    0,    3, ...,   11,   24,    1],\n",
       "       [  53,    1,   13, ...,    1,    0, 1500]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = NN_model_Adam.predict_classes(X_test)\n",
    "confusion_matrix(Y_test.argmax(axis=1), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12646dc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'], 'b-', label=\"training\")\n",
    "plt.plot(hist.history['val_loss'], 'r:', label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'val_loss: 2.135098670959971'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'val_loss: '+str(hist.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12622cdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['acc'], 'b-', label=\"training\")\n",
    "plt.plot(hist.history['val_acc'], 'r:', label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'val_acc: 0.6646982031140154'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'val_acc: '+str(hist.history['val_acc'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2089197e-09, 2.0131631e-15, 1.6364732e-13, ..., 7.2006501e-14,\n",
       "        2.0836043e-10, 5.7538920e-05],\n",
       "       [3.0320177e-11, 1.8701259e-25, 2.0520984e-18, ..., 1.2581283e-16,\n",
       "        2.3690112e-11, 1.9440484e-14],\n",
       "       [6.4366561e-09, 5.2226441e-09, 8.1764142e-09, ..., 1.0025821e-13,\n",
       "        5.6351299e-11, 2.6507832e-06],\n",
       "       ...,\n",
       "       [9.3903309e-06, 3.6602496e-06, 4.6151545e-05, ..., 9.8783528e-07,\n",
       "        5.1633842e-06, 2.1330957e-04],\n",
       "       [8.9475227e-19, 9.7932412e-36, 1.0395678e-17, ..., 3.1487583e-26,\n",
       "        1.0456165e-18, 1.9727319e-23],\n",
       "       [7.7195085e-15, 3.9071495e-30, 3.3775608e-18, ..., 8.9605318e-14,\n",
       "        9.9120616e-06, 5.8330335e-17]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = NN_model_Adam.predict_proba(csr_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Submission CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TripType_3</th>\n",
       "      <th>TripType_4</th>\n",
       "      <th>TripType_5</th>\n",
       "      <th>TripType_6</th>\n",
       "      <th>TripType_7</th>\n",
       "      <th>TripType_8</th>\n",
       "      <th>TripType_9</th>\n",
       "      <th>TripType_12</th>\n",
       "      <th>TripType_14</th>\n",
       "      <th>TripType_15</th>\n",
       "      <th>TripType_18</th>\n",
       "      <th>TripType_19</th>\n",
       "      <th>...</th>\n",
       "      <th>TripType_34</th>\n",
       "      <th>TripType_35</th>\n",
       "      <th>TripType_36</th>\n",
       "      <th>TripType_37</th>\n",
       "      <th>TripType_38</th>\n",
       "      <th>TripType_39</th>\n",
       "      <th>TripType_40</th>\n",
       "      <th>TripType_41</th>\n",
       "      <th>TripType_42</th>\n",
       "      <th>TripType_43</th>\n",
       "      <th>TripType_44</th>\n",
       "      <th>TripType_999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VisitNumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>191338</th>\n",
       "      <td>1.730229e-13</td>\n",
       "      <td>2.425841e-21</td>\n",
       "      <td>8.429140e-12</td>\n",
       "      <td>1.941777e-18</td>\n",
       "      <td>1.777411e-14</td>\n",
       "      <td>1.059953e-21</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.176596e-11</td>\n",
       "      <td>1.356109e-15</td>\n",
       "      <td>2.683029e-15</td>\n",
       "      <td>2.597601e-11</td>\n",
       "      <td>1.767230e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>3.139897e-08</td>\n",
       "      <td>3.088410e-04</td>\n",
       "      <td>1.768995e-05</td>\n",
       "      <td>6.381227e-10</td>\n",
       "      <td>3.479142e-09</td>\n",
       "      <td>7.997314e-02</td>\n",
       "      <td>1.686088e-02</td>\n",
       "      <td>5.442490e-16</td>\n",
       "      <td>2.577574e-18</td>\n",
       "      <td>6.002039e-23</td>\n",
       "      <td>1.206902e-17</td>\n",
       "      <td>6.795739e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191339</th>\n",
       "      <td>1.388900e-04</td>\n",
       "      <td>3.338453e-16</td>\n",
       "      <td>1.455766e-09</td>\n",
       "      <td>2.772955e-11</td>\n",
       "      <td>6.293660e-12</td>\n",
       "      <td>5.525852e-22</td>\n",
       "      <td>2.371358e-16</td>\n",
       "      <td>5.152682e-08</td>\n",
       "      <td>1.835849e-10</td>\n",
       "      <td>1.314726e-06</td>\n",
       "      <td>2.229205e-06</td>\n",
       "      <td>5.159717e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>2.941609e-09</td>\n",
       "      <td>5.837240e-04</td>\n",
       "      <td>1.229384e-04</td>\n",
       "      <td>6.335146e-06</td>\n",
       "      <td>7.247067e-01</td>\n",
       "      <td>1.625225e-05</td>\n",
       "      <td>1.568347e-02</td>\n",
       "      <td>1.201895e-05</td>\n",
       "      <td>9.987507e-06</td>\n",
       "      <td>2.281035e-03</td>\n",
       "      <td>1.444809e-04</td>\n",
       "      <td>6.028037e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191340</th>\n",
       "      <td>9.390331e-06</td>\n",
       "      <td>3.660250e-06</td>\n",
       "      <td>4.615154e-05</td>\n",
       "      <td>1.156958e-03</td>\n",
       "      <td>3.630771e-04</td>\n",
       "      <td>3.444595e-03</td>\n",
       "      <td>5.511248e-06</td>\n",
       "      <td>1.171573e-04</td>\n",
       "      <td>6.150435e-06</td>\n",
       "      <td>7.940399e-04</td>\n",
       "      <td>9.242965e-06</td>\n",
       "      <td>4.602914e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.090776e-03</td>\n",
       "      <td>9.773116e-01</td>\n",
       "      <td>5.108481e-03</td>\n",
       "      <td>2.193251e-03</td>\n",
       "      <td>5.712534e-04</td>\n",
       "      <td>2.797878e-03</td>\n",
       "      <td>2.691462e-05</td>\n",
       "      <td>5.111526e-07</td>\n",
       "      <td>1.079574e-06</td>\n",
       "      <td>9.878353e-07</td>\n",
       "      <td>5.163384e-06</td>\n",
       "      <td>2.133096e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191341</th>\n",
       "      <td>8.947523e-19</td>\n",
       "      <td>9.793241e-36</td>\n",
       "      <td>1.039568e-17</td>\n",
       "      <td>1.069797e-17</td>\n",
       "      <td>3.261707e-14</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.246382e-11</td>\n",
       "      <td>5.188666e-21</td>\n",
       "      <td>1.683380e-06</td>\n",
       "      <td>1.167836e-11</td>\n",
       "      <td>5.103340e-19</td>\n",
       "      <td>...</td>\n",
       "      <td>3.370024e-14</td>\n",
       "      <td>1.843260e-03</td>\n",
       "      <td>1.201489e-13</td>\n",
       "      <td>3.917889e-06</td>\n",
       "      <td>8.603221e-08</td>\n",
       "      <td>3.466093e-11</td>\n",
       "      <td>7.090525e-02</td>\n",
       "      <td>1.617062e-19</td>\n",
       "      <td>5.944025e-29</td>\n",
       "      <td>3.148758e-26</td>\n",
       "      <td>1.045616e-18</td>\n",
       "      <td>1.972732e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191348</th>\n",
       "      <td>7.719508e-15</td>\n",
       "      <td>3.907150e-30</td>\n",
       "      <td>3.377561e-18</td>\n",
       "      <td>2.685287e-25</td>\n",
       "      <td>2.499538e-17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.235152e-26</td>\n",
       "      <td>1.569394e-10</td>\n",
       "      <td>3.886438e-17</td>\n",
       "      <td>2.713177e-13</td>\n",
       "      <td>4.311670e-10</td>\n",
       "      <td>2.178945e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>4.495937e-14</td>\n",
       "      <td>2.538578e-19</td>\n",
       "      <td>6.435293e-11</td>\n",
       "      <td>5.062590e-10</td>\n",
       "      <td>4.205940e-07</td>\n",
       "      <td>3.872478e-12</td>\n",
       "      <td>3.013779e-08</td>\n",
       "      <td>1.376041e-06</td>\n",
       "      <td>4.465802e-14</td>\n",
       "      <td>8.960532e-14</td>\n",
       "      <td>9.912062e-06</td>\n",
       "      <td>5.833033e-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               TripType_3    TripType_4    TripType_5    TripType_6  \\\n",
       "VisitNumber                                                           \n",
       "191338       1.730229e-13  2.425841e-21  8.429140e-12  1.941777e-18   \n",
       "191339       1.388900e-04  3.338453e-16  1.455766e-09  2.772955e-11   \n",
       "191340       9.390331e-06  3.660250e-06  4.615154e-05  1.156958e-03   \n",
       "191341       8.947523e-19  9.793241e-36  1.039568e-17  1.069797e-17   \n",
       "191348       7.719508e-15  3.907150e-30  3.377561e-18  2.685287e-25   \n",
       "\n",
       "               TripType_7    TripType_8    TripType_9   TripType_12  \\\n",
       "VisitNumber                                                           \n",
       "191338       1.777411e-14  1.059953e-21  0.000000e+00  2.176596e-11   \n",
       "191339       6.293660e-12  5.525852e-22  2.371358e-16  5.152682e-08   \n",
       "191340       3.630771e-04  3.444595e-03  5.511248e-06  1.171573e-04   \n",
       "191341       3.261707e-14  0.000000e+00  0.000000e+00  3.246382e-11   \n",
       "191348       2.499538e-17  0.000000e+00  8.235152e-26  1.569394e-10   \n",
       "\n",
       "              TripType_14   TripType_15   TripType_18   TripType_19  \\\n",
       "VisitNumber                                                           \n",
       "191338       1.356109e-15  2.683029e-15  2.597601e-11  1.767230e-14   \n",
       "191339       1.835849e-10  1.314726e-06  2.229205e-06  5.159717e-07   \n",
       "191340       6.150435e-06  7.940399e-04  9.242965e-06  4.602914e-06   \n",
       "191341       5.188666e-21  1.683380e-06  1.167836e-11  5.103340e-19   \n",
       "191348       3.886438e-17  2.713177e-13  4.311670e-10  2.178945e-11   \n",
       "\n",
       "                 ...        TripType_34   TripType_35   TripType_36  \\\n",
       "VisitNumber      ...                                                  \n",
       "191338           ...       3.139897e-08  3.088410e-04  1.768995e-05   \n",
       "191339           ...       2.941609e-09  5.837240e-04  1.229384e-04   \n",
       "191340           ...       2.090776e-03  9.773116e-01  5.108481e-03   \n",
       "191341           ...       3.370024e-14  1.843260e-03  1.201489e-13   \n",
       "191348           ...       4.495937e-14  2.538578e-19  6.435293e-11   \n",
       "\n",
       "              TripType_37   TripType_38   TripType_39   TripType_40  \\\n",
       "VisitNumber                                                           \n",
       "191338       6.381227e-10  3.479142e-09  7.997314e-02  1.686088e-02   \n",
       "191339       6.335146e-06  7.247067e-01  1.625225e-05  1.568347e-02   \n",
       "191340       2.193251e-03  5.712534e-04  2.797878e-03  2.691462e-05   \n",
       "191341       3.917889e-06  8.603221e-08  3.466093e-11  7.090525e-02   \n",
       "191348       5.062590e-10  4.205940e-07  3.872478e-12  3.013779e-08   \n",
       "\n",
       "              TripType_41   TripType_42   TripType_43   TripType_44  \\\n",
       "VisitNumber                                                           \n",
       "191338       5.442490e-16  2.577574e-18  6.002039e-23  1.206902e-17   \n",
       "191339       1.201895e-05  9.987507e-06  2.281035e-03  1.444809e-04   \n",
       "191340       5.111526e-07  1.079574e-06  9.878353e-07  5.163384e-06   \n",
       "191341       1.617062e-19  5.944025e-29  3.148758e-26  1.045616e-18   \n",
       "191348       1.376041e-06  4.465802e-14  8.960532e-14  9.912062e-06   \n",
       "\n",
       "             TripType_999  \n",
       "VisitNumber                \n",
       "191338       6.795739e-20  \n",
       "191339       6.028037e-12  \n",
       "191340       2.133096e-04  \n",
       "191341       1.972732e-23  \n",
       "191348       5.833033e-17  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subform_df_columns = samplesub.columns[1:]\n",
    "result_df = pd.DataFrame(result)\n",
    "result_df.columns = subform_df_columns\n",
    "subform_df = pd.concat([test.reset_index()['VisitNumber'],result_df],axis=1)\n",
    "subform_df.set_index('VisitNumber',inplace=True)\n",
    "subform_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "subform_df.to_csv('./NN/Adam_cat_cro_den{}_lr{}_epo{}_batch_size{}.csv'\n",
    "                  .format(dense,lr,epochs,batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model_Adadelta.save('./NN/Adam_cat_cro_den{}_lr{}_epo{}_basi{}.hdf5'.format(dense,lr,epochs,batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./NN/Adam_cat_cro_den{}_lr{}_epo{}_basi{}.hdf5'.format(dense,lr,epochs,batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24, 32,  5, ..., 31,  0, 37])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
